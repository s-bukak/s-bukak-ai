from transformers import GPT2TokenizerFast
import tensorflow as tf

# 모델과 토크나이저 로드
model_path = '/content/drive/MyDrive/Alpha/Korean/vdcnn_model_with_kogpt2.h5'
tokenizer = GPT2TokenizerFast.from_pretrained("skt/kogpt2-base-v2")

# `pad_token` 설정
if tokenizer.pad_token is None:
    tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # '[PAD]' 추가
tokenizer.pad_token_id = 0  # ID 0은 일반적으로 안전한 선택

model = tf.keras.models.load_model(model_path)

# 텍스트 전처리 함수
def preprocess_text(text):
    return text.lower()

# 문장이 욕설인지 판별하는 함수
def predict_text(text):
    sentence = preprocess_text(text)
    inputs = tokenizer.encode_plus(
        sentence,
        max_length=1000,
        padding="max_length",
        truncation=True,
        return_tensors="tf"
    )
    prediction = model.predict(inputs['input_ids'])[0][0]
    print("예측 값:", prediction)
    return prediction

# 입력 반복
while True:
    text = input("문장을 입력해 주세요: ")
    result = predict_text(text)
    if result >= 0.975:
        print("욕설입니다")
    else:
        print("욕설이 아닙니다")
